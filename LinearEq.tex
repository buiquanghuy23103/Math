\chapter{Linear equations}
\section{Linear independent set}
Let $X$ be any vector space. If vectors $\vect{a_1},\vect{a_2},\ldots ,\vect{a_n} \in X$, then for any scalars $s_1,s_2,\ldots ,s_n \in \mathbb{R}$, the vector
\[ \vect{x}=\sum^n_{i=1}s_i \vect{a_i} \]
is called \emph{a linear combination} of $\vect{a_1},\vect{a_2},\ldots ,\vect{a_n}$.
Let $S$ be a set of vectors $S=\lbrace \vect{a_1},\vect{a_2},\ldots ,\vect{a_n} \rbrace$, where all vectors in $S$ belong to the same vector space $X$. Denote the zero-element of vector space $X$ as $\overline{0}$. If the set $S$ is \emph{linearly independent} then   a linear combination of vectors in $S$ equals zero-element if and only if all scalars in the linear combination are zero.
\[ \sum^n_{i=1}s_i \vect{a_i} = \overline{0} \Leftrightarrow s_i = 0, \forall i \in \lbrace 1,2,\ldots ,n \rbrace \]
\begin{example}
Let $X=\mathbb{R}^2$ and $S=\lbrace \vect{a_1},\vect{a_2}\rbrace$, where $\vect{a_1}=(2,4)$ and $\vect{a_2}=(1,2)$. We have
\begin{meq*}
    s_1\vect{a_1} + s_2\vect{a_2} = \overline{0} & \Leftrightarrow & s_1\cvect{2,4} + s_2\cvect{1,2} = \cvect{0,0} \\
    \Leftrightarrow
    \begin{cases}         
        2s_1 + s_2 &= 0 \\                    
        4s_1 + 2s_2 &= 0                      
    \end{cases}                           
    & \Leftrightarrow & s_2=-2s_1                   
\end{meq*}
Thus, the set $S$ is not linearly independent. Notice that the equation $s_2=-2s_1 $ indicates $\vect{a_1},\vect{a_2}$ are on the same line in the two-dimensional coordinate system. We can use $\vect{a_1}$ to define $\vect{a_2}$ based on the equation $s_2=-2s_1$, and vice versa $\vect{a_1}$ can be defined by $\vect{a_2}$.
\end{example}
\begin{example}
Let $X=\mathbb{R}^2$ be a vector space and $S=\lbrace \vect{a_1},\vect{a_2}\rbrace$, where $\vect{a_1}=(2,4)$ and $\vect{a_2}=(-1,2)$. We have
\begin{meq*}
    s_1\vect{a_1} + s_2\vect{a_2} = \overline{0} & \Leftrightarrow & s_1\cvect{2,4} + s_2\cvect{1,2} = \cvect{0,0} \\
    \Leftrightarrow
    \begin{cases}         
        2s_1 - s_2 &= 0 \\                    
        4s_1 + 2s_2 &= 0                      
    \end{cases}                           
    & \Leftrightarrow &
    \begin{cases}         
        s_2 &= 2s_1 \\                    
        s_2 &= -2s_1                      
    \end{cases}
    \Leftrightarrow s_2=s_1=0                  
\end{meq*}
Thus, the set $S$ is linearly independent. Notice that the equation $s_2=s_1=0$ indicates there is no way to define $\vect{a_1}$ using $\vect{a_2}$, or vice versa.
\end{example}
\begin{example}
Show that vectors $\vect{u},\vect{v}\in \mathbb{R}^5$ does not form a linearly independent set if $\vect{u}=(-1,0,8,5,2)$ and $\vect{v}=(-6,0,48,30,12)$.\par 
The set $\lbrace \vect{u},\vect{v} \rbrace$ is linearly independent if and only if
\begin{equation}
\label{ex1-5}
s_1\vect{u} + s_2\vect{v} = \overline{0} \Leftrightarrow s_1=s_2=0
\end{equation}
We have $s_1\vect{u} + s_2\vect{v} = \overline{0}$ is equivalent to
\begin{equation*}
\begin{cases}
-s_1-6s_2 &=0 \\
8s_1+48s_2 &=0 \\
5s_1+30s_2 &=0 \\
2s_1+12s_2 &=0
\end{cases}
\end{equation*}
All of these equations are equivalent to $s_1+6s_2=0$. There are an infinite number of solutions to this equations, which does not satisfies \eqref{ex1-5}.
\end{example}
Let $X$ be a vector space and the set $A \subseteq X$ is linearly independent. If any vectors $\vect{u}\in X$ is a linear combination of vectors in $A$, then $A$ is a \emph{base of X}. 
\section{System of linear equations}
\label{linear-eq}
Given $\vect{A}$ an n-square matrix and two column vectors $\vect{x}=\rvect{x_1,x_2,\ldots ,x_n}^T$ and $\vect{b}=\rvect{b_1,b_2,\ldots ,b_n}^T$. The system of n linear equations in n unknowns is equivalent to the matrix equation: \[ \vect{A}\vect{x}=\vect{b} \]
The matrix $\vect{A}$ is called the \emph{coefficient matrix}. The properties of this matrix, especially determinant, decide the solution of the equation.\par The collection of all columns in $\vect{A}$ form a lineary independent set (rank of $\vect{A}$ is n) if and only if $\dt{A}\neq 0$. This also means that there exists a unique solution for the equation. On the other hand, if $\dt{A}=0$, then either of two cases occurs: the system has no solutions, or there are an infinite number of solutions.\par There are many ways to solve a system of equations, however, in this notebook, only three solutions related to matrix are mentioned: Inverse matrix, Crammer's rule, Gaussian elimination.
\subsection{Inverse matrix}
Given the matrix equation $\vect{A}\vect{x}=\vect{b}$ where $\vect{A}$ is an n-square matrix, $\vect{x}=\rvect{x_1,x_2,\ldots ,x_n}^T$ and $\vect{b}=\rvect{b_1,b_2,\ldots ,b_n}^T$. If  $\dt{A}\neq 0$, then $\vect{A}$ is invertible and there is a unique solution to the equation: \[ \vect{x}=\inverse{A}\vect{b} \]
Observe that this method only works if the determinant of the coefficient matrix is nonzero.
\begin{example}
Solve the following system of equation:
\begin{equation}
\begin{cases}
    2x_1+4x_2 &= 8 \\
    7x_1-2x_2 &= 4
\end{cases}
\label{apple}
\end{equation}
Let define matrix $\vect{A}$, $\vect{x}$, and $\vect{b}$ as follow:
\[ \vect{A}=\smtrx{2,4\\ 7,-2} \quad \vect{x}=\cvect{x_1,x_2} \quad \vect{b}=\cvect{8,4} \]
The system of equations is equivalent to 
\begin{equation*}
\vect{A}\vect{x}=\vect{b}
\end{equation*}
The determinant of coefficient matrix is \[ \dt{A}=2\cdot (-2) - 7\cdot 4= -32 \neq 0 \] Thus, the equation has a unique solution, which is
\[ \vect{x}=\inverse{A}\vect{b}=\frac{1}{-32} \smtrx{-2,-4\\-7,2}\cvect{8,4}=\cvect{1,3/2} \]
\end{example}
\subsection{Crammer's rule}
Suppose we need to solve the matrix equation $\vect{A}\vect{x}=\vect{b}$ where $\vect{A}$ is an n-square matrix, $\vect{x}=\rvect{x_1,x_2,\ldots ,x_n}^T$ and $\vect{b}=\rvect{b_1,b_2,\ldots ,b_n}^T$. Let $\vect{A}^{(j)}$ be a matrix $\vect{A}$ but replace \emph{j}th column with $\vect{b}$. Then we have \[ x_j=\frac{\dt{\vect{A}^{(j)}}}{\dt{A}} \] Like Inverse matrix, this method only works if the determinant of the coefficient matrix is nonzero.
\begin{example}
The system of equation \eqref{apple} can solved using Crammer's rule as follow:
\begin{meq*}
    \vect{A} &=& \smtrx{2,4\\7,-2}, \quad \dt{A}=-32 \\
    \dt{A^{(1)}} &=& \dmtrx{8,4\\4,-2}=-32 \Rightarrow x_1=\frac{-32}{-32}=1 \\
    \dt{A^{(2)}} &=& \dmtrx{2,7\\8,4}=-48 \Rightarrow x_2=\frac{-48}{-32}=\frac{3}{2}
\end{meq*}
\end{example}
\subsection{Gaussian elimination}
Gaussian elimination (also known as row reduction) is an algorithm for solving systems of linear equations. It is usually understood as a sequence of operations performed on the corresponding matrix of coefficients. This method can also be used to find the rank of a matrix, to calculate the determinant of a matrix, and to calculate the inverse of an invertible square matrix.\par
To perform Gaussian elimination, one uses a sequence of elementary row operations to modify the matrix until the lower left-hand corner of the matrix is filled with zeros, as much as possible. There are three types of elementary row operations:
\begin{itemize}
\item Swap the positions of two rows.
\item Multiply a row by a nonzero scalar.
\item Add to one row a scalar multiple of another.
\end{itemize}
These operations are already shown in section \ref{sec:Determinants} as properties of determinants.\par 
\begin{example}
The system of equation \eqref{apple} can solved using Gaussian elimination. Let define matrix $\vect{A}$, $\vect{x}$, and $\vect{b}$ as follow:
\[ \vect{A}=\smtrx{2,4\\ 7,-2} \quad \vect{x}=\cvect{x_1,x_2} \quad \vect{b}=\cvect{8,4} \] 
First, we create the augmented matrix which is formed by merging matrix $\vect{A}$ and $\vect{b}$.
\begin{equation*}
    \left[{\begin{array}{cc|c}
        2&4&8 \\ 7&-2&4
    \end{array}}\right]
\end{equation*}
Swap the positions of two rows, we have:
\begin{equation*}
    \left[{\begin{array}{cc|c}
        7&-2&4 \\ 2&4&8
    \end{array}}\right]
\end{equation*}
Multiply the first row by 1/7, we have:
\begin{equation*}
    \left[{\begin{array}{cc|c}
        1&-2/7&4/7 \\ 2&4&8
    \end{array}}\right]
\end{equation*}
Replace the second row by $R_2 \leftarrow R_2-2R_1$
\begin{equation*}
    \left[{\begin{array}{cc|c}
        1&-2/7&4/7 \\ 0&32/7&48/7
    \end{array}}\right]
\end{equation*}
Multiply the first row by 32/7, we have:
\begin{equation*}
    \left[{\begin{array}{cc|c}
        1&-2/7&4/7 \\ 0&1&48/32
    \end{array}}\right]
\end{equation*}
Replace the first row by $R_1 \leftarrow R_2+ \frac{2}{7} R_1$
\begin{equation*}
    \left[{\begin{array}{cc|c}
        1&0&1 \\ 0&1&48/32
    \end{array}}\right]
\end{equation*}
Thus, $x_1=1$ and $x_2=48/32$.
\end{example}
